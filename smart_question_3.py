# -*- coding: utf-8 -*-
"""dats6103_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TEQ3nHnTS06B85P90KIiDdcMf8CqnnJC
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, PolynomialFeatures

# Load the data
data = pd.read_csv('diabetes_012_health_indicators_BRFSS2015.csv')
data

# Basic statistics
print("Basic Descriptive Statistics:\n\n")
print(data.describe())

# Checking for missing values
print("\nMissing Values:")
print(data.isnull().sum())

# Correlation matrix
plt.figure(figsize=(16, 12))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Distribution of education and income
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
sns.countplot(x='Education', data=data)
plt.title('Distribution of Education Levels')

plt.subplot(1, 2, 2)
sns.countplot(x='Income', data=data)
plt.title('Distribution of Income Levels')
plt.show()

# Relationship between Education and Health (MentHlth, PhysHlth)
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
sns.violinplot(x='Education', y='MentHlth', data=data)
plt.title('Mental Health by Education Level')

plt.subplot(1, 2, 2)
sns.violinplot(x='Education', y='PhysHlth', data=data)
plt.title('Physical Health by Education Level')
plt.show()

# Relationship between Income and Health (MentHlth, PhysHlth)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
sns.violinplot(x='Income', y='MentHlth', data=data)
plt.title('Mental Health by Income Level')

plt.subplot(1, 2, 2)
sns.violinplot(x='Income', y='PhysHlth', data=data)
plt.title('Physical Health by Income Level')
plt.show()

data['Edu_Income_Interaction'] = data['Education'] * data['Income']

scaler = StandardScaler()
data[['Education', 'Income', 'Edu_Income_Interaction']] = scaler.fit_transform(data[['Education', 'Income', 'Edu_Income_Interaction']])

print("Updated Descriptive Statistics with Feature Engineering:")
print(data[['Education', 'Income', 'Edu_Income_Interaction']].describe())

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report


# Assuming 'MentHlth' has been transformed to a binary outcome in the dataset
data['MentHlthBinary'] = (data['MentHlth'] > 0).astype(int)

# Feature matrix and target variable
X = data[['Education', 'Income', 'Edu_Income_Interaction']]
y = data['MentHlthBinary']

# Scaling the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Splitting the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Initialize and fit Logistic Regression model
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)

# Predict on the testing set
y_pred = log_reg.predict(X_test)

# Evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", report)

from sklearn.preprocessing import PolynomialFeatures
import pandas as pd

# Assume 'data' is your DataFrame and you're using the 'Education' and 'Income' columns
poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
X_poly = poly.fit_transform(data[['Education', 'Income']])  # Add more features as needed

# Replace 'get_feature_names' with 'get_feature_names_out'
data_poly = pd.DataFrame(X_poly, columns=poly.get_feature_names_out(['Education', 'Income']))
data_updated = pd.concat([data.drop(['Education', 'Income'], axis=1), data_poly], axis=1)

# Now 'data_updated' contains the original data with added polynomial features

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score


# Assuming 'MentHlth' has been transformed into a binary outcome in the dataset
data_updated['MentHlthBinary'] = (data_updated['MentHlth'] > 0).astype(int)

# Features and target variable
X = data_updated[['Education', 'Income', 'Edu_Income_Interaction']]
y = data_updated['MentHlthBinary']

# Splitting the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# Initialize the Random Forest Classifier
rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42, class_weight='balanced')

# Train the model
rf_classifier.fit(X_train, y_train)

# Make predictions
y_pred = rf_classifier.predict(X_test)
y_prob = rf_classifier.predict_proba(X_test)[:, 1]  # probabilities for ROC AUC

# Evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_prob)

print("Accuracy:", accuracy, "\n\n")
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", class_report)
print("ROC AUC Score:", roc_auc)

import matplotlib.pyplot as plt
import seaborn as sns

# Feature importance from the Random Forest model
feature_importances = rf_classifier.feature_importances_
feature_names = X.columns

# Create a pandas series to visualize feature importances
importances = pd.Series(feature_importances, index=feature_names)

# Plotting
plt.figure(figsize=(8, 6))
importances.sort_values().plot(kind='barh', color='lightblue')
plt.title('Feature Importance in Random Forest Model')
plt.xlabel('Importance')
plt.show()

from sklearn.metrics import ConfusionMatrixDisplay

# Visualize the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=rf_classifier.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix for Random Forest Classifier')
plt.show()

from sklearn.metrics import roc_curve, auc

fpr, tpr, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)  # Calculate the AUC (Area under the curve)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

from sklearn.metrics import precision_recall_curve, average_precision_score

precision, recall, thresholds = precision_recall_curve(y_test, y_prob)
average_precision = average_precision_score(y_test, y_prob)

plt.figure()
plt.step(recall, precision, where='post', label='Precision-Recall curve (AP = %0.2f)' % average_precision)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title('Precision-Recall Curve')
plt.legend(loc="upper right")
plt.show()

